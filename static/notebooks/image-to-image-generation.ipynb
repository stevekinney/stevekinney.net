{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMB9id9Mh/JB1aAndSks7kx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Image-to-Image Transformations\n","\n","We can also use our pipelines to take existing images and use them as inspiration to generate new images."],"metadata":{"id":"ExHrwcmWjgLp"}},{"cell_type":"code","source":["# @title Import Libraries and Set Everything Up\n","\n","import matplotlib.pyplot as plt\n","from diffusers import StableDiffusionImg2ImgPipeline, StableDiffusionPipeline\n","from google.colab import output\n","import torch\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Clear CUDA cache to free up GPU memory, just in case we run this multiple times.\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()"],"metadata":{"id":"m89HxrkKjOht"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We're going to use two different pipelines for this:\n","\n","- `StableDiffusionPipeline`: for generating an image from a text prompt.\n","- `StableDiffusionImg2ImgPipeline`: for modifying an existing image based on a new prompt and a strength parameter."],"metadata":{"id":"35uGLNZikAuU"}},{"cell_type":"code","source":["model_id = \"runwayml/stable-diffusion-v1-5\"\n","\n","# Load the text-to-image pipeline\n","text_to_image_pipe = StableDiffusionPipeline.from_pretrained(\n","    model_id,\n","    torch_dtype=torch.float16,\n","    use_safetensors=True\n",").to(device)\n","\n","# Load the image-to-image pipeline\n","img_to_img_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n","    model_id,\n","    torch_dtype=torch.float16,\n","    use_safetensors=True\n",").to(device)"],"metadata":{"id":"lyYRUVOokYW0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_prompt = \"a simple sketch of a house\" # @param {type:\"string\"}\n","transform_prompt = \"a futuristic glass house with neon lights, cyberpunk style\" # @param {type:\"string\"}"],"metadata":{"cellView":"form","id":"h5XsR5t9qQTI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The second pipeline has the model weights, but a different pipeline—this one accepts an existing image and transforms it based on a prompt and strength setting. Let's generate an image to start out with."],"metadata":{"id":"NxjhDvZikkh1"}},{"cell_type":"code","source":["base_image = text_to_image_pipe(base_prompt).images[0]\n","\n","base_image"],"metadata":{"id":"adFhBu6akvmj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["I'm going to set up a quick diagram so that we can see the results at various differents strengths."],"metadata":{"id":"HAIURUA0llYY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PfPkQyqjgpA0"},"outputs":[],"source":["strengths = [0.3, 0.5, 0.7]\n","\n","# Set up a plot so we can see all of the different strengths.\n","fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n","\n","# Show original\n","axes[0].imshow(base_image)\n","axes[0].set_title(\"Original\")\n","axes[0].axis('off')\n","\n","# Generate a new image a each of the different strengths.\n","for i, strength in enumerate(strengths):\n","    print(f\"Transforming with strength {strength}…\")\n","    transformed = img_to_img_pipe(\n","        prompt=transform_prompt,\n","        image=base_image,\n","        strength=strength,\n","        guidance_scale=7.5\n","    ).images[0]\n","\n","    axes[i+1].imshow(transformed)\n","    axes[i+1].set_title(f\"Strength: {strength}\")\n","    axes[i+1].axis('off')\n","\n","output.clear()\n","\n","plt.suptitle(\"Image-to-Image Transformation\", fontsize=16)\n","plt.tight_layout()\n","plt.show()"]}]}